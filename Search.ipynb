{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2eea3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file './mlruns/1/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nicolasd/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/nicolasd/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/nicolasd/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/nicolasd/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/nicolasd/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/mlflow/utils/yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/1/meta.yaml' does not exist.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129096/4150552418.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mva_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Sanity {model_name}] AUC ~ {auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;31m# Lance une sanity rapide (tu peux changer \"lgbm\" en \"rf\"/\"logreg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m \u001b[0msanity_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lgbm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;31m# -----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_129096/4150552418.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     ])\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mtr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mva_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mva_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Sanity {model_name}] AUC ~ {auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1362\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 )\n\u001b[1;32m   1364\u001b[0m             ):\n\u001b[0;32m-> 1365\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0;34m\"`sklearn.set_config(enable_metadata_routing=True)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             )\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 last_step_params = self._get_metadata_for_step(\n",
      "\u001b[0;32m~/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0musing\u001b[0m \u001b[0ma\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# shallow copy of steps - this should really be steps_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Setup the memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mtransformers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             if not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not hasattr(\n\u001b[1;32m    338\u001b[0m                 \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/scoring_project7/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tuning Notebook — Projet 7\n",
    "# - Préprocessing: `basic_feature_engineering`\n",
    "# - Score métier normalisé (FN & FP)\n",
    "# - VarianceThreshold après OHE\n",
    "# - Randomized/Grid Search\n",
    "# - MLflow local par défaut (sécurise l'exécution)\n",
    "\n",
    "# %%\n",
    "import os, sys, time, json, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Permet d'importer src/* quand on lance depuis un notebook\n",
    "ROOT = Path(\".\").resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Imports projet\n",
    "# -----------------------------\n",
    "import yaml\n",
    "from src.features import basic_feature_engineering\n",
    "from src.metrics import make_business_scorer, evaluate_all\n",
    "# Si tu as un module data.py, on lit simplement les CSV via conf\n",
    "# from src.data import load_training_data  # (si tu en as un)\n",
    "# met ça tout en haut du notebook, AVANT tout import mlflow\n",
    "MLFLOW_DIR = \"./mlruns_tune\"           # nouveau répertoire\n",
    "Path(MLFLOW_DIR).mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:{MLFLOW_DIR}\"\n",
    "os.environ[\"MLFLOW_EXPERIMENT\"]   = \"tuning_local\"\n",
    "\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "CONF_PATH = \"conf/params.yaml\"\n",
    "\n",
    "with open(CONF_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "def cfg_get(d, path, default=None):\n",
    "    cur = d\n",
    "    for p in path.split(\".\"):\n",
    "        if isinstance(cur, dict) and p in cur:\n",
    "            cur = cur[p]\n",
    "        else:\n",
    "            return default\n",
    "    return cur\n",
    "\n",
    "TRAIN_CSV = cfg_get(cfg, \"data.train_csv\")\n",
    "TARGET    = \"TARGET\"  # adapté au dataset Home Credit\n",
    "FN_COST   = float(cfg_get(cfg, \"cost.fn\", 10.0))\n",
    "FP_COST   = float(cfg_get(cfg, \"cost.fp\", 1.0))\n",
    "TH_GRID   = int(cfg_get(cfg, \"cost.threshold_grid\", 501))\n",
    "\n",
    "N_SPLITS  = int(cfg_get(cfg, \"cv.n_splits\", 5))\n",
    "RSTATE    = int(cfg_get(cfg, \"cv.random_state\", 42))\n",
    "\n",
    "# ---------------- MLflow (local par défaut) ----------------\n",
    "USE_MLFLOW_REMOTE = False  # mets True si tu veux loguer sur Databricks\n",
    "EXPERIMENT_NAME   = \"tuning_local\"\n",
    "\n",
    "if not USE_MLFLOW_REMOTE:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"file:./mlruns\"\n",
    "    os.environ[\"MLFLOW_EXPERIMENT\"]   = EXPERIMENT_NAME\n",
    "\n",
    "import mlflow\n",
    "\n",
    "if USE_MLFLOW_REMOTE:\n",
    "    # suppose que tes variables env Databricks sont déjà OK dans ce notebook\n",
    "    mlflow.set_tracking_uri(cfg_get(cfg, \"mlflow.default_tracking_uri\", \"databricks\"))\n",
    "    mlflow.set_experiment(cfg_get(cfg, \"mlflow.default_experiment\", \"/Users/.../projet7_scoring\"))\n",
    "else:\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Chargement & Préprocessing\n",
    "# -----------------------------\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "assert TARGET in df.columns, f\"Colonne cible '{TARGET}' absente.\"\n",
    "\n",
    "y = df[TARGET].astype(int).reset_index(drop=True)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "preprocessor = basic_feature_engineering(X)\n",
    "\n",
    "# On ajoute un VarianceThreshold APRÈS le transformer (marche sur sparse)\n",
    "var_filter = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Scorer métier normalisé\n",
    "# -----------------------------\n",
    "business_scorer = make_business_scorer(\n",
    "    fn_cost=FN_COST,\n",
    "    fp_cost=FP_COST,\n",
    "    grid=TH_GRID\n",
    ")\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Aides: builders d'estimateurs\n",
    "# -----------------------------\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def build_lgbm_for_search(y):\n",
    "    pos = int(np.sum(y == 1))\n",
    "    neg = int(np.sum(y == 0))\n",
    "    spw = neg / max(pos, 1)  # stabilise les splits pour données déséquilibrées\n",
    "    return lgb.LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=RSTATE,\n",
    "        min_gain_to_split=0.0,  # IMPORTANT pour éviter \"best gain: -inf\"\n",
    "        verbosity=-1,\n",
    "        scale_pos_weight=spw,   # plutôt que class_weight\n",
    "    )\n",
    "\n",
    "def build_logreg_for_search():\n",
    "    return LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"saga\",\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RSTATE,\n",
    "    )\n",
    "\n",
    "def build_rf_for_search():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        n_jobs=-1,\n",
    "        random_state=RSTATE,\n",
    "        class_weight=\"balanced\",\n",
    "        oob_score=False,\n",
    "    )\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Espaces de recherche\n",
    "# -----------------------------\n",
    "def lgbm_space(random=True):\n",
    "    if random:\n",
    "        return {\n",
    "            \"clf__num_leaves\": randint(63, 255),\n",
    "            \"clf__max_depth\": randint(8, 16),          # -1 si tu veux illimité -> ajoute une valeur\n",
    "            \"clf__min_child_samples\": randint(5, 100),\n",
    "            \"clf__subsample\": uniform(0.6, 0.4),       # 0.6..1.0\n",
    "            \"clf__colsample_bytree\": uniform(0.6, 0.4),\n",
    "            \"clf__reg_lambda\": loguniform(1e-3, 10),\n",
    "            \"clf__reg_alpha\": loguniform(1e-3, 10),\n",
    "            \"clf__max_bin\": randint(128, 512),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"clf__num_leaves\": [63, 127, 255],\n",
    "            \"clf__max_depth\": [8, 12, -1],\n",
    "            \"clf__min_child_samples\": [5, 20, 50, 100],\n",
    "            \"clf__subsample\": [0.6, 0.8, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"clf__reg_lambda\": [0.01, 0.1, 1.0, 10.0],\n",
    "            \"clf__reg_alpha\": [0.0, 0.01, 0.1, 1.0],\n",
    "            \"clf__max_bin\": [128, 255, 512],\n",
    "        }\n",
    "\n",
    "def logreg_space(random=True):\n",
    "    if random:\n",
    "        return {\n",
    "            \"clf__C\": loguniform(1e-3, 1e+2),\n",
    "            \"clf__l1_ratio\": uniform(0.0, 1.0),  # si penalty='elasticnet' (optionnel)\n",
    "            # si tu veux tester elasticnet:\n",
    "            # \"clf__penalty\": [\"l1\", \"l2\", \"elasticnet\"],  # attention combinaisons solver\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"clf__C\": [0.01, 0.1, 1.0, 10.0, 50.0, 100.0],\n",
    "        }\n",
    "\n",
    "def rf_space(random=True):\n",
    "    if random:\n",
    "        return {\n",
    "            \"clf__max_depth\": randint(6, 20),\n",
    "            \"clf__min_samples_leaf\": randint(1, 50),\n",
    "            \"clf__min_samples_split\": randint(2, 50),\n",
    "            \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "            \"clf__n_estimators\": randint(300, 900),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"clf__max_depth\": [8, 12, 16, None],\n",
    "            \"clf__min_samples_leaf\": [1, 2, 5, 10, 20],\n",
    "            \"clf__min_samples_split\": [2, 5, 10, 20],\n",
    "            \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "            \"clf__n_estimators\": [300, 500, 700, 900],\n",
    "        }\n",
    "\n",
    "def get_estimator_by_name(name: str):\n",
    "    if name == \"lgbm\":\n",
    "        import lightgbm as lgb\n",
    "        return lgb.LGBMClassifier(\n",
    "            n_estimators=1500, learning_rate=0.03, num_leaves=64,\n",
    "            subsample=0.8, colsample_bytree=0.8, class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif name == \"rf\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=400, max_depth=None, n_jobs=-1, class_weight=\"balanced\"\n",
    "        )\n",
    "    elif name == \"logreg\":\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression(\n",
    "            penalty=\"l2\", solver=\"saga\", max_iter=2000,\n",
    "            class_weight=\"balanced\", n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {name}\")\n",
    "\n",
    "def sanity_fit(model_name=\"lgbm\"):\n",
    "    # Objets NEUFS (pas de fit_transform ici)\n",
    "    prep = basic_feature_engineering(X)         # <- transformeur\n",
    "    var_sel = VarianceThreshold(threshold=0.0)  # <- transformeur\n",
    "    est = get_estimator_by_name(model_name)     # <- estimateur\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", var_sel if prep is None else prep),  # au cas où\n",
    "        (\"var\", var_sel),\n",
    "        (\"est\", est),\n",
    "    ])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    tr_idx, va_idx = next(iter(skf.split(X, y)))\n",
    "    pipe.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "    proba = pipe.predict_proba(X.iloc[va_idx])[:, 1]\n",
    "    auc = roc_auc_score(y.iloc[va_idx], proba)\n",
    "    print(f\"[Sanity {model_name}] AUC ~ {auc:.4f}\")\n",
    "\n",
    "# Lance une sanity rapide (tu peux changer \"lgbm\" en \"rf\"/\"logreg\")\n",
    "sanity_fit(\"lgbm\")\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Recherche (Randomized ou Grid)\n",
    "# -----------------------------\n",
    "SEARCH_MODE = \"random\"   # \"random\" ou \"grid\"\n",
    "MODEL       = \"lgbm\"     # \"lgbm\" | \"logreg\" | \"rf\"\n",
    "N_ITER      = 40         # utilisé si random\n",
    "N_JOBS      = 4          # safe pour desktop; ajuste selon ta machine\n",
    "VERBOSE_CV  = 1\n",
    "\n",
    "if MODEL == \"lgbm\":\n",
    "    clf = build_lgbm_for_search(y)\n",
    "    space = lgbm_space(random=(SEARCH_MODE==\"random\"))\n",
    "elif MODEL == \"logreg\":\n",
    "    clf = build_logreg_for_search()\n",
    "    space = logreg_space(random=(SEARCH_MODE==\"random\"))\n",
    "elif MODEL == \"rf\":\n",
    "    clf = build_rf_for_search()\n",
    "    space = rf_space(random=(SEARCH_MODE==\"random\"))\n",
    "else:\n",
    "    raise ValueError(\"MODEL ∈ {lgbm, logreg, rf}\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"var\", VarianceThreshold(0.0)),\n",
    "    (\"clf\", clf),\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RSTATE)\n",
    "\n",
    "if SEARCH_MODE == \"random\":\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=space,\n",
    "        n_iter=N_ITER,\n",
    "        scoring=business_scorer,         # métrique métier normalisée\n",
    "        cv=cv,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=VERBOSE_CV,\n",
    "        refit=True,\n",
    "        random_state=RSTATE,\n",
    "    )\n",
    "else:\n",
    "    search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=space,\n",
    "        scoring=business_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=VERBOSE_CV,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "t0 = time.time()\n",
    "with mlflow.start_run(run_name=f\"tune_{MODEL}_{SEARCH_MODE}\") as run:\n",
    "    mlflow.log_params({\n",
    "        \"model\": MODEL,\n",
    "        \"search_mode\": SEARCH_MODE,\n",
    "        \"n_splits\": N_SPLITS,\n",
    "        \"n_iter\": N_ITER if SEARCH_MODE==\"random\" else None,\n",
    "        \"n_jobs\": N_JOBS,\n",
    "        \"fn_cost\": FN_COST,\n",
    "        \"fp_cost\": FP_COST,\n",
    "        \"th_grid\": TH_GRID,\n",
    "    })\n",
    "    search.fit(X, y)\n",
    "    dur = time.time() - t0\n",
    "\n",
    "    best_score = float(search.best_score_)\n",
    "    best_params = search.best_params_\n",
    "    mlflow.log_metric(\"best_business_score\", best_score)\n",
    "    mlflow.log_metric(\"search_secs\", dur)\n",
    "    mlflow.log_dict(best_params, \"best_params.json\")\n",
    "\n",
    "    print(f\"\\n✅ DONE in {dur/60:.1f} min\")\n",
    "    print(f\"Best business score (normalized): {best_score:.4f}\")\n",
    "    print(\"Best params:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  - {k}: {v}\")\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# Évaluation AUC / métriques sur CV refit (train complet)\n",
    "# -----------------------------\n",
    "best_model = search.best_estimator_\n",
    "proba_all = np.zeros(len(y), dtype=float)\n",
    "\n",
    "fold_rows = []\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X, y), 1):\n",
    "    m = best_model\n",
    "    # Refit par fold (séparé du refit global) pour sortir des métriques propres\n",
    "    m.fit(X.iloc[tr_idx], y[tr_idx])\n",
    "    p = m.predict_proba(X.iloc[va_idx])[:, 1]\n",
    "    proba_all[va_idx] = p\n",
    "    fold_auc = roc_auc_score(y[va_idx], p)\n",
    "    fold_rows.append({\"fold\": fold, \"auc\": fold_auc})\n",
    "\n",
    "fold_df = pd.DataFrame(fold_rows)\n",
    "overall_auc = roc_auc_score(y, proba_all)\n",
    "\n",
    "print(\"\\nAUC par fold:\")\n",
    "display(fold_df)\n",
    "print(f\"Overall AUC OOF: {overall_auc:.4f}\")\n",
    "\n",
    "# Score métier (normalisé) + seuil optimal sur OOF\n",
    "m_oof = evaluate_all(y_true=y, y_prob=proba_all,\n",
    "                     fn_cost=FN_COST, fp_cost=FP_COST,\n",
    "                     threshold_grid=TH_GRID)\n",
    "print(\"\\nMétriques OOF (extrait):\")\n",
    "for k in [\"auc\", \"ap\", \"brier\", \"ks\", \"business_score_norm\", \"best_threshold\"]:\n",
    "    if k in m_oof:\n",
    "        print(f\"  {k}: {m_oof[k]}\")\n",
    "\n",
    "# Sauvegarde artifacts locaux utiles\n",
    "ART_DIR = Path(\"reports\")\n",
    "ART_DIR.mkdir(exist_ok=True, parents=True)\n",
    "np.save(ART_DIR/\"oof_prob.npy\", proba_all)\n",
    "with open(ART_DIR/\"tuning_summary.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"model\": MODEL,\n",
    "        \"search_mode\": SEARCH_MODE,\n",
    "        \"best_business_score_norm\": float(m_oof.get(\"business_score_norm\", float(\"nan\"))),\n",
    "        \"best_threshold\": float(m_oof.get(\"best_threshold\", float(\"nan\"))),\n",
    "        \"overall_auc_oof\": float(overall_auc)\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nArtifacts sauvegardés dans ./reports/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoring_project7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
